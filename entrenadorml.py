# -*- coding: utf-8 -*-
"""EntrenadorML

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XjAqGXZUMXWW2qjWQva676Z-fFW8bDnf
"""

!sudo apt install tesseract-ocr
!pip install pytesseract
!apt-get install poppler-utils
!sudo apt install pdf2image
!pip install pdf2image
# from google.colab import drive
# drive.mount('/content/drive')


from matplotlib import pyplot as plt
import matplotlib.ticker as plticker

import cv2
import matplotlib.image as mpimg 
import matplotlib as mpl
from google.colab.patches import cv2_imshow
from PIL import Image
import requests
import shutil
from sklearn import linear_model
import ipywidgets as widgets 
from matplotlib.colors import ListedColormap

import tensorflow as tf

import numpy as np 

import os

import matplotlib.pyplot as plt

import os
import codecs
import re


import pdf2image
# import datefinder
try:
    from PIL import Image
except ImportError:
    import Image
import pytesseract


tipodeDocumentos = ['CARTA DE ADJUDICACION','CONTRATOS','COTIZACION','FACTURAS','NOTA DE ENTREGA','ORDEN DE COMPRA']

#tipodeDocumentos = ['ads','asd']

def plot_graphs(history, metric):
  plt.plot(history.history[metric])
  plt.plot(history.history['val_'+metric], '')
  plt.xlabel("Epochs")
  plt.ylabel(metric)
  plt.legend([metric, 'val_'+metric])


def simplificar(contenido):
  aux = contenido
  palabrasDes = ["de","del","a","DE","DEL","A","en","EN","EL","el","LA","la","y","Y","o","se","para","PARA","Las","para","con","por","que","Los"]
  for i in range(len(palabrasDes)):
    aux = aux.replace(' '+palabrasDes[i]+' ', ' ').lstrip(palabrasDes[i]+' ').rstrip(' '+palabrasDes[i])
  numeros = ["1","2","3","4","5","6","7","8","9","0"]
  for j in range(len(numeros)):
    aux = aux.replace(numeros[j],"")

  return(aux)

def pdf_to_img(pdf_file):
  return pdf2image.convert_from_path(pdf_file)

def ocr_core(file):
  text = pytesseract.image_to_string(file)
  if len(text) > 15:
    return text
  else:
    return ''

def leerpdf(pdf_file):
  completo = """"""
  images = pdf_to_img(pdf_file)
  for pg, img in enumerate(images):
    images = pdf_to_img(pdf_file)
    completo = completo + ocr_core(img)
  return simplificar(completo)

def entrenar():
  train_data=[]
  global tipodeDocumentos
  pathAbsoluto="/content/drive/MyDrive/EntrenamientoSelector"
  os.listdir(pathAbsoluto)
  for i in os.listdir(pathAbsoluto):
    cont = 0
    pos = tipodeDocumentos.index(i)
    pathaux=pathAbsoluto+"/"+i
    for j in os.listdir(pathaux):
      cont = cont + 1
      pathaux2 = pathaux+"/"+j
      train_data.append([np.array(leerpdf(pathaux2).encode()),pos])
      if round(len(os.listdir(pathaux)) / 1.25) == cont:
        break
  return train_data

def testeo():
  test_data=[]
  global tipodeDocumentos
  pathAbsoluto="/content/drive/MyDrive/EntrenamientoSelector"
  os.listdir(pathAbsoluto)
  for i in os.listdir(pathAbsoluto):
    cont = 0
    pos = tipodeDocumentos.index(i)
    pathaux=pathAbsoluto+"/"+i
    for j in reversed(os.listdir(pathaux)):
      cont = cont + 1
      pathaux2 = pathaux+"/"+j
      test_data.append([np.array(leerpdf(pathaux2).encode()),pos])
      if round(len(os.listdir(pathaux)) / 5) == cont:
        break
  return test_data

# array_Txts=[]
# array_Texto=[]
# numero_pagina=[]
# test_dataset=[]
# # 0 es factura 
# # 1 es cotizacion 
# # 2 pedido loca
# contenido = os.listdir()
# for fichero in contenido:
#     if os.path.isfile(os.path.join("", fichero)) and fichero.endswith('.txt'):
#         array_Txts.append(fichero)
# # print(array_Txts)
# train_data=[]
# for i in array_Txts:
#   with open(i,'r',encoding="latin-1") as f:
#     if i[0]=="0": 
#         train_data.append([np.array(simplificar(f.read()).encode()),0])
#         numero_pagina.append(i)
#     if i[0]=="1": 
#         train_data.append([np.array(simplificar(f.read()).encode()),1])
#         numero_pagina.append(i)
#     if i[0]=="2": 
#         train_data.append([np.array(simplificar(f.read()).encode()),2])

#         numero_pagina.append(i)
    
#     if i[:4] == "test":
#         aux=i[:5]
#         # print(aux[4],"valor")
#         if aux[4]=="0":
#           #test_dataset.append([np.array(simplificar(f.read()).encode()),0])
#           test_dataset.append([np.array(simplificar(f.read()).encode()),0])
#         if aux[4]=="1":
#           test_dataset.append([np.array(simplificar(f.read()).encode()),1])
#         if aux[4]=="2":
#           test_dataset.append([np.array(simplificar(f.read()).encode()),2])



# print("longitud de train",len(train_data))
# print("longitud test ",len(test_dataset))
# # print(train_data)


train_array_str=[]
train_array_int=[]
test_array_str=[]
test_array_int=[]

for e,l in testeo():
  test_array_str.append(e)
  test_array_int.append(l)

train_data = entrenar()
for e,l in train_data:
  train_array_str.append(e)
  train_array_int.append(l)


strTrain = tf.convert_to_tensor(train_array_str, dtype=tf.string)
LabelsTrain = tf.convert_to_tensor(train_array_int, dtype=tf.int32)
strTest = tf.convert_to_tensor(test_array_str, dtype=tf.string)
LabelTest = tf.convert_to_tensor(test_array_int, dtype=tf.int32)


test_dataset2 = tf.data.Dataset.from_tensor_slices((strTest, LabelTest))
train_dataset2=tf.data.Dataset.from_tensor_slices((strTrain, LabelsTrain))

for example, label in test_dataset2.take(1):
  print('text: ', example.numpy())
  print('label: ', label.numpy())

BUFFER_SIZE = 10000
BATCH_SIZE = 15

VOCAB_SIZE = 1000

############33antigua_forma
train_sirve=[]
for e,l in train_data:
  train_sirve.append(e)

train_dataset2 = train_dataset2.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
test_dataset2 = test_dataset2.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

for example, label in train_dataset2.take(1):
  print('texts: ', example.numpy()[:3])
  print()
  print('labels: ', label.numpy()[:3])

encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(
    max_tokens=VOCAB_SIZE)
encoder.adapt(train_dataset2.map(lambda text, label: text))

vocab = np.array(encoder.get_vocabulary())
vocab[:20]

model = tf.keras.Sequential([
    encoder,
    tf.keras.layers.Embedding(
        input_dim=len(encoder.get_vocabulary()),output_dim=BATCH_SIZE,mask_zero=False),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(BATCH_SIZE)),
    tf.keras.layers.Dense(BATCH_SIZE, activation='relu'),
    #tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(6, activation='softmax')
])

model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              optimizer=tf.keras.optimizers.Adam(1e-4),
              metrics=['accuracy'])

history = model.fit(train_dataset2, epochs=200,
                    validation_data=test_dataset2,
                    validation_steps=30)

test_loss, test_acc = model.evaluate(test_dataset2)

print('Test Loss:', test_loss)
print('Test Accuracy:', test_acc)

plt.figure(figsize=(16, 8))
plt.subplot(1, 2, 1)
plot_graphs(history, 'accuracy')
plt.ylim(None, 1)
plt.subplot(1, 2, 2)
plot_graphs(history, 'loss')
plt.ylim(0, None)

texts=""" 

Pil Andina S.A. Num. Pedido / Fecha Pag.
NIT: 1020757027 4425260218 / 16.10.2017 2



Pos Material Descripcién
Cantidad Unidad de medida Costo Unitario Importe

 

Notas:
1. Nota de entrega + Certificado de Calidad/Andlisis + Copia del Pedido de Compra (En Almacén Central Recepcion Pil Andina S.A. de cada p
2. Factura + Copia del Pedido de Compra (Entregar en COP-Contabilidad Pil Andina S.A. de cada Planta).

- COCHABAMBA: Wilfredo Soliz - Leonardo Anzaldo.

- LA PAZ: Trifon Ordofiez - Lizett Escobar.

- SANTA CRUZ: Roxana Arana - Ana Romero.
3. Los materiales podran ser entregados en Almacén Central Recepcidn Pil Andina S.A. de cada planta en el horario de 08:00 a 16:00 de lunes
viernes y de 08:00 a 12:00 los sabados.
4, Factura a entregar junto con la mercaderia sera aceptada en COP-Contabilidad Pil Andina S.A. en el horario de 08:00 a 16:00 de lunes a vie
(mismo horario de recepcién de Almacenes).
5. Factura a entregar posterior a la recepcidn de la mercaderia sera aceptada en COP-Contabilidad Pil Andina S.A. solamente los dias viernes
horario de 08:00 a 12:00.
"""
predictions = model.predict(np.array([texts]))


print (predictions)

from tensorflow.keras.models import load_model
from tensorflow.keras.models import save_model

model.save('test/modelo',save_format='tf')

# model.save('my_model.h5')
# model.save_weights('/test/modelo_weight.h5')

!zip -r /content/aea.zip  /content/test

# import os

# tipodeDocumentos = ['CARTA DE ADJUDICACION','CONTRATOS','COTIZACION','FACTURAS','NOTA DE ENTREGA','ORDEN DE COMPRA']

# pathAbsoluto="/content/drive/MyDrive/EntrenamientoSelector"
# os.listdir(pathAbsoluto)
# for i in os.listdir(pathAbsoluto):
#   cont = 0
#   pos = tipodeDocumentos.index(i)
#   pathaux=pathAbsoluto+"/"+i
#   for j in reversed(os.listdir(pathaux)):
#     cont = cont + 1
#     pathaux2 = pathaux+"/"+j
#     print("pos: ", pos, "numero: ", cont)
#     if round(len(os.listdir(pathaux)) / 5) == cont:
#       break

#  print("el modulo es: ",len(os.listdir(pathaux)))

